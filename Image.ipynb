{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZECgUgpqG3n",
        "outputId": "7d59ca9d-cfa2-4941-8219-6ff63356acd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEuFcdP4BOvn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torchvision.models.resnet import ResNet50_Weights\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rand_seed = 6\n",
        "np.random.seed(rand_seed)\n",
        "random.seed(rand_seed)\n",
        "torch.manual_seed(rand_seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(rand_seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "lrsri3cXU-qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "FffhpMLrHiL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    # transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "ahHYCvBJCu3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, features, labels, transform):\n",
        "    self.features = features\n",
        "    self.labels = labels\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.features)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.transform(self.features[idx]), self.labels[idx]"
      ],
      "metadata": {
        "id": "NsXxEadEI-xB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('/content/drive/Shareddrives/TFQ/MemeSEN/multi-sent.xlsx')"
      ],
      "metadata": {
        "id": "Yivh82tkJVW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {'neutral': 0, 'positive': 1, 'negative': 2}"
      ],
      "metadata": {
        "id": "CLiXApR3YG1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Xi = [i for i in data['image_name']]\n",
        "Xi = np.load('/content/drive/Shareddrives/TFQ/Model_Checkpoints/Resized_224_Normalized.npy')\n",
        "Xc = [i for i in data['Captions']]\n",
        "Y = [label_map[i] for i in data['Label_Sentiment']]"
      ],
      "metadata": {
        "id": "5LLFfw4KKD1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_preprocess(image):\n",
        "  # path = '/content/drive/MyDrive/MemeSEN/Memes/' + path\n",
        "  # image = cv2.imread(path)\n",
        "  # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  # image = Image.fromarray(image)\n",
        "  # image = image.astype(np.uint8)\n",
        "  return resnet_transform(image)"
      ],
      "metadata": {
        "id": "qZQR7gf-bvEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Xi = np.load('/content/drive/MyDrive/MemeSEN/ResNet50_Processed_Xi.npy')\n",
        "# Xi = [image_preprocess(i) for i in Xi]\n",
        "# Xi_numpy = [i.numpy() for i in Xi]\n",
        "# np.save('/content/drive/MyDrive/MemeSEN/ResNet50_Processed_Xi.npy', Xi_numpy)"
      ],
      "metadata": {
        "id": "_l234e-wX3p3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xi_train, Xi_test, Y_train, Y_test = train_test_split(Xi, Y, test_size=0.3, random_state=6, stratify=Y)\n",
        "Xi_test, Xi_valid, Y_test, Y_valid = train_test_split(Xi_test, Y_test, test_size=1/3, random_state=6, stratify=Y_test)"
      ],
      "metadata": {
        "id": "GrB8aA-7KZ8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampler(object):\n",
        "    def __init__(self, data_source):\n",
        "        pass\n",
        "\n",
        "    def __iter__(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def __len__(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "class StratifiedSampler(Sampler):\n",
        "    def __init__(self, class_vector, batch_size):\n",
        "        self.n_splits = int(class_vector.size(0) / batch_size)\n",
        "        self.class_vector = class_vector\n",
        "\n",
        "    def gen_sample_array(self):\n",
        "        s = StratifiedShuffleSplit(n_splits=self.n_splits, test_size=0.5)\n",
        "        X = torch.randn(self.class_vector.size(0),2).numpy()\n",
        "        y = self.class_vector.numpy()\n",
        "        s.get_n_splits(X, y)\n",
        "\n",
        "        train_index, test_index = next(s.split(X, y))\n",
        "        return np.hstack([train_index, test_index])\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(self.gen_sample_array())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.class_vector)"
      ],
      "metadata": {
        "id": "QzLlrH7aUzwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=48\n",
        "\n",
        "sampler = StratifiedSampler(class_vector=torch.tensor(Y_train), batch_size=batch_size)\n",
        "train_loader = DataLoader(CustomDataset(Xi_train, Y_train, image_preprocess), batch_size=batch_size, sampler=sampler)\n",
        "valid_loader = DataLoader(CustomDataset(Xi_valid, Y_valid, image_preprocess), batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(CustomDataset(Xi_test, Y_test, image_preprocess), batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "1L9SBL3CK-lX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50 = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
        "\n",
        "num_features = resnet50.fc.in_features\n",
        "resnet50.fc = nn.Linear(num_features, 3)\n",
        "resnet50.to(device)"
      ],
      "metadata": {
        "id": "NFhPSc_LCcQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet_v3 = models.mobilenet_v3_large(weights=models.MobileNet_V3_Large_Weights.IMAGENET1K_V1)\n",
        "num_features = mobilenet_v3.classifier[3].in_features\n",
        "mobilenet_v3.classifier[3] = nn.Linear(num_features, 3)\n",
        "mobilenet_v3.to(device)"
      ],
      "metadata": {
        "id": "Lj8-o_0p6PFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "densenet161 = models.densenet161(weights=models.DenseNet161_Weights.IMAGENET1K_V1)\n",
        "num_features = densenet161.classifier.in_features\n",
        "densenet161.classifier = nn.Linear(num_features, 3)\n",
        "densenet161.to(device)"
      ],
      "metadata": {
        "id": "Q72PzJ37APLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(np.array(Y)), y=Y)\n",
        "# criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weights, dtype=torch.float32, device=device))\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(densenet161.parameters(),\n",
        "                              lr=0.00001,\n",
        "                              betas=(0.9, 0.9999),\n",
        "                              eps=1e-09,\n",
        "                              weight_decay=0.08)"
      ],
      "metadata": {
        "id": "j5XS8J7JG3f8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/Shareddrives/TFQ/Model_Checkpoints/DenseNet/'\n",
        "def train_model(model, start, end, name):\n",
        "  for epoch in range(start, end):\n",
        "      model.train()\n",
        "      running_loss = 0.0\n",
        "      for inputs, labels in train_loader:\n",
        "          inputs = inputs.to(device)\n",
        "          # print(labels)\n",
        "          labels = labels.to(device)\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(inputs)\n",
        "          # print(outputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          running_loss = loss.item()\n",
        "\n",
        "\n",
        "      model.eval()\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      with torch.no_grad():\n",
        "          for inputs, labels in valid_loader:\n",
        "              inputs = inputs.to(device)\n",
        "              labels = labels.to(device)\n",
        "              outputs = model(inputs)\n",
        "              _, predicted = torch.max(outputs, 1)\n",
        "              total += labels.size(0)\n",
        "              correct += (predicted == labels).sum().item()\n",
        "\n",
        "      val_accuracy = correct / total\n",
        "      torch.save(model.state_dict(), path + f'{name}_{epoch + 1}.pkl')\n",
        "      print(f\"Epoch {epoch + 1}/{end}, Loss: {running_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "Ym5yilFbHikF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(densenet161, 0, 10, 'densenet161')"
      ],
      "metadata": {
        "id": "56XNM1S07g3x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfaacb39-ac59-4821-d710-4587c05b4f47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.8210, Validation Accuracy: 0.7162\n",
            "Epoch 2/10, Loss: 0.7779, Validation Accuracy: 0.7140\n",
            "Epoch 3/10, Loss: 0.6802, Validation Accuracy: 0.7094\n",
            "Epoch 4/10, Loss: 0.5688, Validation Accuracy: 0.7094\n",
            "Epoch 5/10, Loss: 0.5700, Validation Accuracy: 0.7162\n",
            "Epoch 6/10, Loss: 0.4410, Validation Accuracy: 0.7025\n",
            "Epoch 7/10, Loss: 0.4226, Validation Accuracy: 0.7025\n",
            "Epoch 8/10, Loss: 0.3190, Validation Accuracy: 0.7025\n",
            "Epoch 9/10, Loss: 0.1666, Validation Accuracy: 0.7117\n",
            "Epoch 10/10, Loss: 0.1908, Validation Accuracy: 0.7048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_report(model, weight):\n",
        "    model.load_state_dict(torch.load(weight))\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            y_true.extend(labels.tolist())\n",
        "            y_pred.extend(predicted.tolist())\n",
        "    return f'{confusion_matrix(y_true, y_pred)}\\n{classification_report(y_true, y_pred)}'"
      ],
      "metadata": {
        "id": "eVUFl0TYWGSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_report(densenet161, '/content/drive/Shareddrives/TFQ/Model_Checkpoints/DenseNet/densenet161_9.pkl'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqGnErw0mNXE",
        "outputId": "7da1630d-d422-432f-d2db-3a702549e7d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   3  55]\n",
            " [  1 153 116]\n",
            " [  1  67 478]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        58\n",
            "           1       0.69      0.57      0.62       270\n",
            "           2       0.74      0.88      0.80       546\n",
            "\n",
            "    accuracy                           0.72       874\n",
            "   macro avg       0.47      0.48      0.47       874\n",
            "weighted avg       0.67      0.72      0.69       874\n",
            "\n"
          ]
        }
      ]
    }
  ]
}